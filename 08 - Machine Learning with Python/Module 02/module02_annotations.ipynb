{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Linear Regression\n",
    "Usamos a regressao linear para tentar prever um valor continuo, baseado nas caracteristicas fornecidas. Nela, temos a variavel dependente (y) que queremos prever, e variaveis independentes (x) que utilizamos como previsoras.\n",
    "\n",
    "Basicamente, existem dois tipos de modelo de regressao:\n",
    "- Regressao Simples: Eh quando usamos uma variavel independente para prever uma variavel dependente. Pode ser Linear ou Nao-Linear.\n",
    "- Regressao Multipla: Eh quando usamos multiplas variaveis independentes para prever uma variavel dependente. Tambem pode ser Linear ou Nao-Linear\n",
    "\n",
    "## Regressao Linear Simples\n",
    "A formula da regressao linear eh dada por:\n",
    "$$\n",
    "\\hat{y} = \\beta_0 + \\beta_1 x\n",
    "$$\n",
    "Essa formula descreve a relacao entre a variavel dependente yhat e a variavel independente x, usando uma reta. On yhat eh o valor previsto, B0 eh o coeficiente linear da reta, e o B1 eh o coeficiente angular da reta, e x eh a variavel preditora.\n",
    "\n",
    "Dessa forma, a regressao linear tenta encontrar os valores de B0 e B1 que minimizam a distancia de erro dos valores observados e previstos, que eh onde usamos o MSE para quantificar este erro.\n",
    "\n",
    "\n",
    "Abaixo, segue a formula do MSE.\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2\n",
    "$$\n",
    "O MSE eh uma metrica para avaliar a precisao de um modelo de regressao. Faz isso atraves do calculo da diferenca entre os valores observados e os valores previstos pela nossa regressao. Ele eh calculado pela media dos quadrados dessas diferencas. Um MSE baixo indica que os valores previstos estao proximos dos valores observados, em contra partida, um MSE alto indica que os valores previstos estao distantes dos valores observados."
   ],
   "id": "fde85b3d2ce1eebf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation\n",
    "Vamos verificar duas formas de avaliacao: treino e teste no mesmo dataset, e train_test_split.\n",
    "\n",
    "__Treino e Teste no mesmo dataset__:\n",
    "\n",
    "Treinamos o modelo usando o mesmo conjunto de dados. Ou seja, utilizamos todos os dados disponiveis para ajustar os parametros do modelo, e seu desempenho eh avaliado com base nesses __mesmos dados__.\n",
    "- Vantagem: Simplicidade\n",
    "- Desvantagem: O modelo pode facilmente acabar em Overfitting. Isso faz com que o modelo tenha uma alta acuracia nos dados de treino, mas uma acuracia ruim ao inputarmos dados que ele nao viu antes.\n",
    "\n",
    "__Train/Test Split__:\n",
    "\n",
    "Neste caso, separamos uma parte dos dados para treino e outra parte dos dados para teste. Essa divisao, geralmente, acaba sendo feita de forma aleatoria, usando uma proporcao de separacao padrao, como 30% para teste e 70% para treino.\n",
    "- Vantagem: Avaliamos o desempenho do modelo com base em dados que ele nao viu no treinamento, o que nos da uma visao melhor da generalizacao.\n",
    "- Desvantagem: Em datasets pequenos, podemos perder a capacidade de ajuste do modelo."
   ],
   "id": "33c6c7402c30faf8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluation Metrics\n",
    "Vamos falar um pouco sobre 3 metricas importantes: MAE (Mean Absolute Error), MSE (Mean Squared Error), RMSE (Root Mean Squared Error).\n",
    "\n",
    "Mas antes disso, o que eh um erro? O erro eh a medida de o quao distante o valor do dado real esta da previsao realizada.  \n",
    "\n",
    "**MAE (Erro Médio Absoluto)**\n",
    "\n",
    "Eh a media do valor absoluto dos erros. Ela calcula a media das diferencas absolutas entre os valores reais e os valores previstos. Ou seja, verifica o quanto as previsoes estao distantes dos valores reais.\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_{\\text{true}} - y_{\\text{pred}}|\n",
    "$$\n",
    "\n",
    "- Vantagem: Nao amplifica grandes erros, pois trabalha com valores absolutos\n",
    "- Desvantagem: Nao considera a direcao do erro.\n",
    "\n",
    "**MSE (Erro Quadrático Médio)**\n",
    "\n",
    "Eh a media dos quadrados das diferencas entre os valores reais e os valores previstos. Ela penaliza grandes erros de forma mais severa, pelo fato de elevar os erros ao quadrado.\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{true}} - y_{\\text{pred}})^2\n",
    "$$\n",
    "\n",
    "- Vantagem: Destaca grandes erros\n",
    "- Desvantagem: Pode dificultar a interpretacao, pois o MSE nao esta na mesma unidade que os dados originais.\n",
    "\n",
    "**RMSE (Raiz do Erro Quadrático Médio)**\n",
    "\n",
    "Eh a raiz quadrada do MSE, o que coloca a metrica de volta na mesma unidade dos dados originais. Ela tambem da mais peso a grandes erros, mas coloca esses erros na mesma unidade que os dados originais, o que facilita nossa interpretacao.\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{true}} - y_{\\text{pred}})^2}\n",
    "$$\n",
    "\n",
    "- Vantagem: Eh mais interpretavel\n",
    "- Desvantagem: Pode exagerar na importancia de grandes erros caso existam outliers.\n",
    "\n",
    "**RAE (Erro Absoluto Relativo)**\n",
    "Eh uma metrica que compara o erro absoluto total de um modelo com o erro absoluto total de um modelo de referencia, que geralmente eh a media dos valores observados. Ele normaliza o erro ao dividir o erro absoluto total das previsoes pelo erro absoluto total em torno da media dos dados reais. Dessa forma, ele mede o quao bem o modelo se sai em relacao a uma previsao basica, como a media de valores reais.\n",
    "\n",
    "$$\n",
    "RAE = \\frac{\\sum |y_i - \\hat{y}_i|}{\\sum |y_i - \\bar{y}|}\n",
    "$$\n",
    "\n",
    "- Vantagem: Possui interpretacao simples, e nao depende da escala dos dados.\n",
    "- Desvantagem: Eh muito influenciado por outliers.\n",
    "\n",
    "**RSE (Erro Quadratico Relativo)**\n",
    "Compara o erro quadratico de um modelo com o erro quadratico de um modelo de referencia, que tambem geralmente eh a media dos valores observados. \n",
    "\n",
    "$$\n",
    "RSE = \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "- Vantagem: Permite comparar o desempenho de um modelo com outro modelo de media, penaliza grandes diferencas entre valores reais e previstos de forma severa.\n",
    "- Desvantagem: Outliers tambem afetam de forma importante essa metrica.\n",
    "\n",
    "**R2 (Coeficiente de Determinacao R2)**\n",
    "\n",
    "Mede a proporcao da variabilidade nos dados que eh explicada pelo modelo. O R2 varia entre valores de 0 e 1, onde 1 significa que o modelo explica toda sua variabilidade, enquanto 0 indica que o modelo nao explica nada sobre a variabilidade.\n",
    "\n",
    "$$\n",
    "R^2 = 1 - RSE\n",
    "$$\n",
    "\n",
    "- Vantagem: Eh de facil interpretacao, e nao eh influenciado pela escala dos dados.\n",
    "- Desvantagem: Nao penaliza o overfitting, pois um valor alto de R2 nao significa necessariamente que o modelo esta generalizavel para novos dados. Em alguns casos, principalmente em modelos ruins, o R2 pode vir a ser negativo,  que indica que o modelo eh pior que usar simplesmente a media dos dados."
   ],
   "id": "36cb546effb24e56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Regressao Linear Multipla\n",
    "Quando possuimos multiplas variaveis independentes, aplicamos a regressao linear multipla. \n",
    "\n",
    "Existem dois tipos de aplicacoes para a regressao linear multipla:\n",
    "- Quando queremos identificar a forca do efeito que as variaveis independentes possuem sobre a variavel dependente.\n",
    "- Prever o impacto de algumas mudancas. Ou seja, enteder como a variavel depentende muda conforme a variavel independente muda tambem.\n",
    "\n",
    "Da mesma forma que a regressao linear simples, o objetivo da multipla eh prever um valor continuo a partir de muitas outras variaveis independentes. A equacao utilizada eh a que segue abaixo.\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\theta^T X\n",
    "$$\n",
    "\n",
    "Para estimar os valores de theta, podemos aplicar o metodo dos Mínimos Quadrados Ordinários. Tambem podemos aplicar algoritmos de otimizacao para encontrar os melhores parametros, como o Gradiente Descendente."
   ],
   "id": "abd4a05672529138"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
