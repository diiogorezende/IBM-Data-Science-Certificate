{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation and Refinement\n",
    "A avaliacao da amostra nos informa o quao bem o modelo se ajusta aos dados de treino. Porem, nao nos informa o quao bem o modelo performa em dados novos.\n",
    "\n",
    "Para contornar isso, fazemos a divisao dos dados em treino e teste. Os dados de treino serao usado para alimentar o modelo e permiti-lo aprender os padroes apresentados pelos dados. Ja os dados de teste serao dados usados para alimentar os modelos apos realizado o treinamento. Dessa forma, podemos avaliar o quao bem o modelo se sai com dados nunca vistos anteriormente.\n",
    "\n",
    "Eh uma pratica comum separar 70% dos dados para a etapa de treinamento, e 30% para a etapa de testes. Porem, isso nao eh uma regra e a separacao vai depender muito da quantidade de dados disponivel, e tambem da distribuicao dos mesmos.\n",
    "\n",
    "Exemplo em codigo da divisao entre treino e teste:\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.3, random_state=42)\n",
    "```\n",
    "\n",
    "- x_data = caracteristicas, ou variaveis independentes, ou variaveis preditoras\n",
    "- y_data = variavel target, ou variavel dependente.\n",
    "\n",
    "__Validacao Cruzada__: Nesta tecnica, o dataset eh dividido em K grupos iguais, cada grupo sendo referido como uma \"pasta\". Para aplicar esta tecnica em codigo, eh da forma que segue abaixo:\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lr, X_data, y_data, cv=5)\n",
    "```\n",
    "O primeiro parametro se refere ao modelo que estamos utilizando, e o parametro \"cv\" se refere a quantidade de folds a serem utilizados. Os outros dois parametros sao as variaveis preditoras e variavel target.\n",
    "\n",
    "A funcao __cross_val_predict()__ retorna a predicao do que foi calculado para cada elemento no conjunto de teste. \n",
    "\n",
    "```\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "yhat = cross_val_predict(lr2e, X_data, y_data, cv=5)\n",
    "```\n",
    "Os parametros que passamos para essa funcao sao os mesmos que passamos na funcao anterior, porem, o resultado exibido por esse funcao sera a previsao."
   ],
   "id": "e61b493709a09bc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Overfitting, Underfitting and Model Selection\n",
    "Como vimos anteriormente, modelos lineares nem sempre sao a melhor opcao. O objetivo de selecionar o modelo correto era determinar a ordem do polinomio que melhor se ajustava aos dados. Naquele exemplo, se utilizassemos uma funcao linear e fosse tracada uma reta, nao haveria um bom ajuste aos dados pois nao temos complexidade o suficiente para isso. Ao avaliarmos isso graficamente, veriamos que haveria um caso de __underfitting__ nos dados.\n",
    "\n",
    "__Underfitting__ ocorre quando o modelo nao apresenta um bom ajuste aos dados, de forma que nao consegue aprender os padroes apresentados nos dados de treino.\n",
    "\n",
    "__Overfitting__ ocorre quando o modelo aprende tanto o padrao dos dados de treino, que acaba se \"viciando\" neles, fazendo com que nao consiga generalizar suas previsoes para os dados de teste. \n",
    "\n",
    "Queremos sempre um modelo que minimize os erros nos dados de teste, de forma que a gente nao tenha um modelo muito \"overfittado\" e nem \"underfittado\". Queremos o meio termo que permita ao modelo uma boa generalizacao para os dados de teste.\n",
    "\n",
    "<br>\n",
    "\n",
    "Codigo para testar diferentes ordens polinomiais:\n",
    "\n",
    "```\n",
    "rs_test = []\n",
    "\n",
    "order = [1, 2, 3, 4]\n",
    "\n",
    "for n in order:\n",
    "    pr = PolynomialFeatures(degree=n)\n",
    "    X_train_pr = pr.fit_transform(X_train[['horsepower']])\n",
    "    X_test_pr = pr.fit_transform(X_test[['horsepower']])\n",
    "    lr.fit(X_train, y_train)\n",
    "    rs_test.append(lr.score(X_test_pr, y_test))\n",
    "```"
   ],
   "id": "9c3f3c13bcc2f3c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ridge Regression\n",
    "A regressao Ridge introduz um parametro chamado __alpha__ que controla a magnitude dos polinomios. O alpha eh um parametro que especificamos antes de treinar o modelo. Conforme o alpha aumenta, a magnitude do polinomio diminui. Porem devemos ter cuidado ao selecionar o valor do alpha e fazer testes com diferentes valores. Isso deve ser feito pois um alpha muito grande pode levar o modelo a um __underfitting__, enquanto um alpha muito baixo pode levar o modelo a um __overfitting__.\n",
    "\n",
    "Codigo para executar essa tarefa:\n",
    "\n",
    "```\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=.1)\n",
    "ridge.fit(X, y)\n",
    "yhat = ridge.predict(X)\n",
    "```"
   ],
   "id": "624115ec79571f29"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Grid Search\n",
    "O parametro _alpha_ na regressao Ridge eh um __hiperparametro__ desse modelo.\n",
    "\n",
    "No scikit-learn existe uma forma de iterar automaticamente por esses parametros usando validacao cruzada, que eh chamado de Grid Search. O __Grid Search__ pega o modelo que queremos treinar, e diferentes valores dos hiperparametros para esse modelo, apos isso, calcula o MSE ou R2 para varios valores dos hiperparametros, permitindo a escolha dos melhores parametros.\n",
    "\n",
    "Para fazer a grid search, criamos um dicionario com os valores que queremos testar dentro de uma lista. A chave deste dicionario sera o nome do hiperparametro, e os valores no dicionario serao uma lista com os valores a serem testados.\n",
    "\n",
    "Codigo para implementacao:\n",
    "\n",
    "```\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = [{'alpha'}: [0.001, 0.1, 1, 10, 100, 1000], 'normalize': [True, False]}] ---> parametros de alpha a serem testados, e a normalizacao.\n",
    "\n",
    "ridge = Ridge() ---> modelo\n",
    "\n",
    "grid = GridSearchCV(ridge, param, cv=5) ---> Aplicacao do modelo e dos parametros no GridSearchCV\n",
    "\n",
    "grid.fit(X_data[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_data) ---> Ajuste\n",
    "\n",
    "grid.best_estimator_ ---> Encontra os melhores valores do parametro\n",
    "\n",
    "scores = grid.cv_results_ ---> Informa o melhor valor de teste\n",
    "\n",
    "scores['mean_test_score']\n",
    "```"
   ],
   "id": "dacaaca0ff81ef54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cedceab275e2ce88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
